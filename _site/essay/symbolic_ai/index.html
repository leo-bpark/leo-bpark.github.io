<!DOCTYPE html>
<!-- _layouts/distill.html -->
<html>
    
<head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>B. Park | Towards Understanding Symbolic AI</title>
    <meta name="author" content="B. Park  " />
    <meta name="description" content="All the baselines and Results" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üëêüèº</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/essay/symbolic_ai/">
    
    <!-- Dark Mode -->
    

    <!-- Social Badges Header Styles -->
    <style>
    .social-badges-header {
        display: flex;
        align-items: center;
        gap: 5px;
        height: 100%;
        line-height: normal;
    }
    
    .nav-item .social-badges-header {
        display: flex;
        align-items: center;
        height: 100%;
    }
    
    .nav-item.social-nav-item {
        margin-right: auto;
        order: -1;
    }
    
    .social-badges-header a {
        text-decoration: none;
        transition: transform 0.2s ease;
    }
    
    .social-badges-header a:hover {
        transform: translateY(-1px);
    }
    
    @media (max-width: 768px) {
        .social-badges-header {
            gap: 3px;
        }
        
        .social-badges-header img {
            height: 20px !important;
        }
    }
    </style>

  <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams',
        inlineMath: [['$','$'], ['\\(','\\)']]
      },
      chtml: {
          scale: 1.0,
          minScale: .6,  
          mtextFontInherit: true,
          mtextInheritFont: true,
          merrorInheritFont: true,
        },
        svg: {
          scale: 1.2
        }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/core-js-bundle@3.30.2/minified.min.js"></script>

  <!-- Distill js -->
  <script src="/assets/js/distillpub/template.v2.js"></script>
  <script src="/assets/js/distillpub/transforms.v2.js"></script>
  <script src="/assets/js/distillpub/overrides.js"></script>
  <!-- Page/Post style -->
  
  <!-- Page/Post style -->
  <style type="text/css">
    .table {
    padding-top:200px;
    margin-bottom: 2.5rem
    border-bottom: 2px;
} .p {
    font-size:20px;
    font-weight: 250;
} .styled-image {
    border-radius: 15px;
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
    margin: 20px auto;
    transition: transform 0.3s ease;
    display: block;
} .styled-image:hover {
    transform: scale(1.2);
} .td .th {
    font-size: 1.10rem;
    font-family: 'Times New Roman', Times, serif;
}

  </style>
</head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "Towards Understanding Symbolic AI",
      "description": "All the baselines and Results",
      "published": "July 2, 2025",
      "authors": [
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body style="padding-top:0px" class="sticky-bottom-footer"> 
    
    <!-- Header --><header>
      
      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
        <div class="container" style="padding-left: 0px; padding-bottom: 0px; margin-bottom: 0px;">
          <img>
          <!-- <img src="/assets/common/KAIST-hi.gif" width="40px" style="margin-right:0px; padding-bottom: 3px;"> -->
          
          <a class="navbar-brand title font-weight-lighter" href="http://localhost:4000/" style="margin-left:20px; padding-bottom: 0px;">
              <!--B. Park-->
           <span class="font-weight-bold" style="font-size:larger;font-family:Times New Roman;">B. Park    </span>
        </a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>
          
            <div class="social-badges-header">
              <a href="https://scholar.google.com/citations?user=XzIXaxoAAAAJ&amp;hl=ko" target="_blank" rel="noopener noreferrer">
                <img src="https://img.shields.io/badge/-000000?style=flat&amp;logo=google-scholar&amp;logoColor=white" alt="Scholar" style="height: 25px; margin-right: 5px;">
              </a>
              <a href="https://x.com/Bumjini" target="_blank" rel="noopener noreferrer">
                <img src="https://img.shields.io/badge/-000000?style=flat&amp;logo=x&amp;logoColor=white" alt="X" style="height: 25px; margin-right: 5px;">
              </a>
              <a href="https://www.linkedin.com/in/bumjin-park-aa093116b/" target="_blank" rel="noopener noreferrer">
                <img src="https://img.shields.io/badge/LinkedIn-000000?style=flat&amp;logo=linkedin&amp;logoColor=white" alt="LinkedIn" style="height: 25px;">
              </a>
              <a href="https://www.instagram.com/bumjini/" target="_blank" rel="noopener noreferrer">
                <img src="https://img.shields.io/badge/-000000?style=flat&amp;logo=instagram&amp;logoColor=white" alt="Instagram" style="height: 25px; margin-right: 5px;">
              </a>
            </div>

          <div class="collapse navbar-collapse text-right" id="navbarNav" style="padding-bottom: 0px; margin-bottom: 0px;">
            <ul class="navbar-nav ml-auto flex-nowrap" style="padding-bottom: 0px; margin-bottom: 0px;">

              <!-- About -->
              <!-- <li style="font-size: 17px" class="nav-item ">
                <a class="nav-link" href="/">  About Me</a>
              </li> -->
              
              <!-- Blog -->

              


              <!-- <li style="font-size: 17px; padding-bottom: 0px; margin-bottom: 0px;" class="nav-item "> -->
                <a class="nav-link" href="/research/" style="padding-bottom: 0px; padding-top: 0px; margin-bottom: 0px; font-family:Times New Roman;">  
                  <img src="/assets/img/logos/campus_icon.png" width="37px" style="margin-right:5px; vertical-align: center;"></a>
              <!-- </li> -->

              <!-- <li style="font-size: 17px; padding-bottom: 0px; margin-bottom: 0px;" class="nav-item "> -->
                <a class="nav-link" href="/essay/" style="padding-bottom: 0px; padding-top: 0px; margin-bottom: 0px; font-family:Times New Roman;"> 
                  <img src="/assets/img/logos/pen_icon.png" width="23px" style="margin-right:5px; vertical-align: center;"></a>
              <!-- </li> -->

              <!-- <li style="font-size: 17px; padding-bottom: 0px; margin-bottom: 0px;" class="nav-item "> -->
                <a class="nav-link" href="/box/" style="padding-bottom: 0px; padding-top: 0px; margin-bottom: 0px; font-family:Times New Roman;"> 
                  <img src="/assets/img/logos/box_icon.png" width="35px" style="margin-right:5px; vertical-align: center;"></a>
              <!-- </li> -->

              <!-- <li style="font-size: 17px; padding-bottom: 0px; margin-bottom: 0px;" class="nav-item ">
                <a class="nav-link" href="/materials/" style="padding-bottom: 0px; margin-bottom: 0px;"> Materials</a>
              </li> -->

              <!-- Other pages -->
              
              <!-- Social Media Badges -->
 
              <!-- Search Icon -->
              <!-- <li style="font-size: 20px; padding-bottom: 0px; margin-bottom: 0px;" class="nav-item"> -->
                <a class="nav-link" href="/search/" style="padding-bottom: 0px; padding-top: 0px; margin-bottom: 0px;">
                  <img src="/assets/img/logos/search_icon.png" width="30px" style="margin-right:5px; margin-bottom: 0px; vertical-align: bottom;">
                  <!-- <i class="fas fa-search"></i> -->
                </a>
              <!-- </li> -->
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1 style="font-size: 32px;">Towards Understanding Symbolic AI</h1>
        <p>All the baselines and Results</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        

        <h2 id="towards-symbolic-ai">Towards Symbolic AI</h2>

<p>With the rapid advancement of artificial intelligence, there is a growing interest in symbolic reasoning. This resurgence is particularly significant because humans tend to learn extensively by understanding, identifying, and forming relationships between symbols. Symbolic AI aims to model such processes by examining the relations among symbols and using formal systems‚Äîsuch as logical or probabilistic inference‚Äîto discover new symbolic connections.</p>

<p>However, a persistent challenge in symbolic AI lies in the complexity of integrating benchmarks and hypotheses that arise from the study of symbols into modern AI systems. Rather than being clearly defined and embedded, these symbolic components are often entangled within broader architectures. For instance, the grounding problem‚Äîhow to ensure that symbols carry meaning‚Äîoffers crucial insight into the semantics and relational structures of symbols, including metaphysical grounding. Analogical reasoning, another key area, involves mapping relationships between symbols metaphorically. This is exemplified by vector-based relational models, such as those found in WordNet or word embedding spaces. In such models, semantic relationships can be captured by vector arithmetic (e.g., the vector from <em>king</em> to <em>queen</em> can be applied to <em>gorilla</em> to yield a new conceptual direction): $P = P_{\text{gorilla}} + V_{\text{queen}}$. This illustrates how symbolic meaning can emerge through transformations in a vector space.</p>

<p>These approaches offer a path toward mapping abstract concepts to symbols. Prior AI systems have explored how internal vector representations may acquire meaning through learning processes (e.g., via toy models), contributing to a deeper understanding of how vectors encode and manipulate conceptual directions.</p>

<p>In contrast, humans have developed rich traditions of dealing with symbols, informed by centuries of philosophical, linguistic, and cognitive research. Symbolic AI can benefit from integrating these traditions, helping large-scale systems like LLMs to better handle symbolic reasoning. This, in turn, could lead to safer, more interpretable, and more efficient model architectures, improved algorithms, and more robust data representations.</p>

<p>Accordingly, the goal of this post is to provide a comprehensive overview of symbolic AI systems, exploring their foundations and offering insights into how they might evolve to support future research and practical applications.</p>

<h2 id="two-branches-of-symbolic-ai">Two Branches of Symbolic AI</h2>

<p><img src="https://d2acbkrrljl37x.cloudfront.net/bumjini-blog/study_post/symbolicAI_overview.png" width="100%" height="auto" class="styled-image"></p>

<h3 id="symbol-grounding-perception-to-symbol-mapping">Symbol Grounding (Perception to Symbol Mapping)</h3>

<p>Harnad (1990) famously posed the symbol grounding problem:
‚ÄúHow can the meanings of words be grounded in anything other than other words?‚Äù</p>

<p>What are differences between the symbol grounding problem and classification tasks? (See the footnote<d-footnote> Symbol Grounding is about how symbols get their meaning, especially from the world and experience. Classification is about how systems assign labels to data, based on patterns in training data.</d-footnote>.)</p>

<p>Symbolic logic systems must search over all possible instantiations of symbols, even when the rules are known.</p>

<p><strong> Algorithm Examples </strong></p>

<ol>
  <li>
    <p><strong>DeepProbLog</strong> (Manhaeve et al., 2018) [<a href="#-algorithm-deepproblog">go below</a>]: The input is processed by a neural predicate <code class="language-plaintext highlighter-rouge">digit(Img, Digit)</code>, which uses a neural network to produce probabilistic outputs. The error is computed after symbolic reasoning via Prolog, and only the neural network parameters are trained.</p>
  </li>
  <li>
    <p><strong>Neuro-Symbolic Concept Learner (NS-CL, Mao, 2019)</strong> [<a href="#-algorithm-ns-cl">go below</a>]:<br>
  Given an image and a natural language question, the system first extracts object-level feature vectors from the image. These features are processed through various <strong>neural operators</strong> (e.g., <code class="language-plaintext highlighter-rouge">ShapeOf(obj)</code>, <code class="language-plaintext highlighter-rouge">ColorOf(obj)</code>) to generate <strong>soft attribute estimates</strong>. In parallel, the natural language question is parsed into a structured program represented in a <strong>domain-specific language (DSL)</strong>,<br>
  which defines a sequence of symbolic operations (e.g., Filter, Relate, Query).  The extracted soft facts‚Äîprobabilistic evaluations of visual concepts‚Äîare then used as inputs to execute the <strong>DSL program</strong>. This execution is performed not by a traditional symbolic engine, but by a <strong>quasi-symbolic executor</strong>, also referred to as a <strong>neuro-symbolic program executor</strong>. This executor evaluates the symbolic program over soft neural outputs,<br>
  enabling differentiable reasoning and end-to-end learning.</p>
  </li>
  <li>
    <p><strong>NS-VQA</strong> (Neuro-Symbolic Visual QA, Yi et al., 2018) [<a href="#-algorithm-ns-vqa">go below</a>]: Uses Mask R-CNN to extract visual features and converts natural language questions into a domain-specific language (DSL) using a GRU-based seq2tree model. The resulting logic program is executed as a symbolic reasoning process via a Python program.</p>
  </li>
  <li>
<strong>LOGIC-LM</strong> (Pan et al., 2023) [<a href="#-algorithm-logic-lm">go below</a>]
A neuro-symbolic reasoning system that combines LLMs with symbolic solvers for faithful logical inference. Shift reasoning execution from LLM to symbolic solvers, leveraging LLMs only for translation (symbol grounding).
    <ul>
      <li>
<strong>Problem Formulator</strong> ‚Äì LLM converts a natural language problem into a symbolic representation (FOL, LP, CSP, SAT).</li>
      <li>
<strong>Symbolic Reasoner</strong> ‚Äì Deterministic symbolic solver (e.g., Prover9, Pyke, Z3) performs logical inference.</li>
      <li>
<strong>Result Interpreter</strong> ‚Äì Maps symbolic result back to natural language.</li>
      <li>
<strong>Self-Refiner</strong> ‚Äì Uses solver error messages to revise invalid symbolic forms via iterative prompting.</li>
    </ul>
  </li>
  <li>
<strong>A-NESI (Krieken et al., 2023)</strong> [<a href="#-algorithm-a-nesi">go below</a>]
(Approximate Neurosymbolic Inference)** is a scalable framework that combines neural networks with <strong>symbolic reasoning</strong> for probabilistic neurosymbolic learning tasks. Unlike traditional methods that rely on <strong>exact inference</strong> and suffer from exponential time complexity, A-NESI uses neural models to perform <strong>approximate inference</strong> in polynomial time. It separates prediction and explanation into two neural components trained on synthetic data generated from background knowledge. Additionally, it supports <strong>logical constraints</strong> at test time through a symbolic pruning mechanism, making it well-suited for safety-critical applications.</li>
</ol>

<h3 id="inductive-logic-program-rule-learning">Inductive Logic Program (Rule Learning)</h3>

<ul>
  <li>
    <p><strong>Inductive Logic Programming</strong>, Muggleton, S. (1991)</p>
  </li>
  <li>
    <p><strong>FOIL</strong>: Learning logical definitions from relations, Quinlan, J. R. (1990)</p>
  </li>
  <li>
    <p><strong>FOCL</strong>:</p>
  </li>
  <li>
    <p><strong>Progol</strong> (Muggleton, 1995)</p>
  </li>
  <li>
    <p><strong>Metagol</strong> system for learning meta-interpreted programs, Cropper, A., &amp; Muggleton, S. (2016)</p>
  </li>
  <li>
    <p><strong>‚àÇILP (Differentiable ILP)</strong> [<a href="#-algorithm-differentiable-ilp">go below</a>]: ‚àÇILP is a differentiable Inductive Logic Programming system that learns symbolic rules from relational data through gradient-based optimization. It replaces discrete inference with differentiable conjunction and disjunction neurons operating over soft truth values. This design enables interpretable rule learning, supports recursion and predicate invention, and generalizes to unseen examples without relying on hand-crafted rule templates.</p>
  </li>
  <li>
    <p><strong>pLogicNet</strong> (not strict ILP because trains a weight for a rule) [<a href="#-algorithm-plogicnet">go below</a>]: pLogicNet is a probabilistic logic neural network that combines the strengths of symbolic logic reasoning and embedding-based knowledge graph completion. It uses predefined logic rules (e.g., composition, inverse, symmetry) and optimizes their weights using a Variational EM algorithm. While it does not learn new rules from scratch, it updates the influence of known rules based on both observed and inferred triples, bridging statistical learning with logical consistency.</p>
  </li>
  <li>
    <p><strong>Neural Theorem Provers</strong>, Rockt√§schel &amp; Riedel, 2017</p>
  </li>
  <li>
    <p>Inductive Logic Programming via Differentiable Forward Chaining, Payani &amp; Fekri (2019)</p>
  </li>
  <li>
    <p>Differentiable Learning of Logical Rules for Knowledge Base Reasoning, Yang, Z. et al. (2017)</p>
  </li>
  <li>
    <p>Logical neural networks, Campero, A. et al. (2018)</p>
  </li>
  <li>
    <p>Learning explanatory rules from noisy data, Evans, R., &amp; Grefenstette, E. (2018)</p>
  </li>
  <li>
    <p>Learning Big Logical Rules by Joining Small Rules, Hocquette, 2024</p>
  </li>
  <li>
    <p><strong>Neural Logic Machines</strong>, Dong, 2019</p>
  </li>
  <li>
    <p>NeuPSL (Neural Probabilistic Soft Logic)</p>
  </li>
  <li>
    <p>LTN (Logic Tensor Networks)</p>
  </li>
  <li>
    <p><strong>A-NESI</strong> : Approximate Neurosymbolic Inference</p>
  </li>
  <li>
    <p><strong>Scallop (Li, 2023)</strong> [<a href="#-algorithm-scallop">go below</a>]: Scallop is a neurosymbolic programming language that integrates deep learning with symbolic reasoning through a differentiable logic framework. It allows users to define logical rules in a Datalog-inspired language and combine them with neural models for end-to-end learning. While users provide templates or rule structures, Scallop learns how to map those to task-specific predicates using training data. Predicate names such as <code class="language-plaintext highlighter-rouge">parent</code> or <code class="language-plaintext highlighter-rouge">ancestor</code> are typically defined in advance, and the system searches for the best combination of these predicates to satisfy a target objective. This makes Scallop suitable for tasks requiring both perceptual grounding and logical generalization, including knowledge reasoning, planning, and multimodal learning.</p>
  </li>
  <li>
    <p><strong>NeSyA: Neurosymbolic Automata</strong></p>
  </li>
</ul>

<hr>

<h3 id="-algorithm-deepproblog">üß† ALGORITHM: DeepProbLog</h3>

<p>Mahaeve proposed Probabilistic Logic Programming (DeepProbLog) in 2018. The algorithm trains a <strong>neural predicate</strong> which is defined by the following format.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nn(m, InputArgs, OutputVar, OutputDomain) :: Predicate.
</code></pre></div></div>

<p>For example, the digit predicate for an image and symbol digit could be defined by:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nn(mnist_net, [Img], Digit, [0,1,2,3,4,5,6,7,8,9]) :: digit(Img, Digit).
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nn(digit_net, [Img], Digit, [0..9]) :: digit(Img, Digit).
nn(op_net, [Img], Op, [+,-,*,/]) :: operator(Img, Op).

solve(E1, E2, E3, Result) :-
    digit(E1, D1),
    digit(E3, D2),
    operator(E2, Op),
    eval(Op, D1, D2, Result).

eval(+, A, B, R) :- R is A + B.
eval(-, A, B, R) :- R is A - B.
</code></pre></div></div>

<hr>

<h3 id="-algorithm-ns-cl">üß† ALGORITHM: NS-CL</h3>

<p>Mao proposed Neuro-Symbolic Concept Learner in 2019.</p>
<ul>
  <li>The natural language question is mapped to a structured symbolic program.</li>
  <li>Execution is performed through differentiable neural operators like <code class="language-plaintext highlighter-rouge">ColorOf()</code> and <code class="language-plaintext highlighter-rouge">PositionOf()</code>.</li>
  <li>The result is a probabilistic symbolic reasoning trace that is fully trainable end-to-end.</li>
</ul>

<p>Consider a color vectors:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Assume 3 color concepts: Red, Blue, Green
</span><span class="n">v_red</span>   <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
<span class="n">v_blue</span>  <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
<span class="n">v_green</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">])</span>
<span class="n">concepts</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">v_red</span><span class="p">,</span> <span class="n">v_blue</span><span class="p">,</span> <span class="n">v_green</span><span class="p">])</span>  <span class="c1"># (3, d)
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Object feature (from ResNet)
</span><span class="n">f_obj</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>  <span class="c1"># example object feature
</span>
<span class="c1"># Predict color distribution
</span><span class="n">color_probs</span> <span class="o">=</span> <span class="nc">ColorOf</span><span class="p">(</span><span class="n">f_obj</span><span class="p">,</span> <span class="n">concepts</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">color_probs</span><span class="p">)</span>  <span class="c1"># e.g., tensor([0.81, 0.15, 0.04])
</span></code></pre></div></div>

<p>We have a question in the form of natural language: 
‚ÄúWhat is the color of the right object?‚Äù It is converted into a DSL form:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># DSL Program:
</span><span class="n">Program</span> <span class="o">=</span> <span class="nc">Query</span><span class="p">(</span><span class="n">Color</span><span class="p">,</span> <span class="nc">Filter</span><span class="p">(</span><span class="n">Rightmost</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Step 2: Apply Filter(Rightmost) - select the rightmost object
</span><span class="n">right_scores</span> <span class="o">=</span> <span class="p">[</span><span class="nc">PositionOf</span><span class="p">(</span><span class="n">obj</span><span class="p">).</span><span class="n">x</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">object_features</span><span class="p">]</span>  <span class="c1"># Get x-coordinate
</span><span class="n">rightmost_index</span> <span class="o">=</span> <span class="nf">argmax</span><span class="p">(</span><span class="n">right_scores</span><span class="p">)</span>                        <span class="c1"># Index of rightmost object
</span><span class="n">mask</span> <span class="o">=</span> <span class="nf">one_hot</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">object_features</span><span class="p">),</span> <span class="n">rightmost_index</span><span class="p">)</span>         <span class="c1"># Binary mask for that object
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Step 3: Apply Query(Color) - predict the color of the selected object
</span><span class="n">selected_feat</span> <span class="o">=</span> <span class="nf">weighted_sum</span><span class="p">(</span><span class="n">object_features</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>       <span class="c1"># Soft selection
</span><span class="n">color_probs</span> <span class="o">=</span> <span class="nc">ColorOf</span><span class="p">(</span><span class="n">selected_feat</span><span class="p">,</span> <span class="n">color_concepts</span><span class="p">)</span>      <span class="c1"># Probability over color concepts
</span>
<span class="c1"># Final Answer:
</span><span class="n">predicted_color</span> <span class="o">=</span> <span class="nf">argmax</span><span class="p">(</span><span class="n">color_probs</span><span class="p">)</span>  <span class="c1"># e.g., "Red"
</span></code></pre></div></div>

<ul>
  <li>
<strong>Question</strong>: Why this algorithm is called Neuro-Symbolic? <d-footnote>  From the visual scene, the algorithm extracts the probability of each symbolic concept, and the natural language question is transformed into a domain-specific language (DSL). This program directly evaluates symbolic conditions, although the evaluation itself is probabilistic.   </d-footnote>
</li>
</ul>

<hr>

<h3 id="-algorithm-logic-lm">üß† ALGORITHM: LOGIC-LM</h3>

<p>Pan et al. introduced LOGIC-LM in 2023.  A neuro-symbolic framework that decouples reasoning from language generation by having LLMs generate symbolic representations, and symbolic solvers execute logical inference.
LOGIC-LM delegates:</p>
<ul>
  <li><strong>Language understanding ‚Üí LLM</strong></li>
  <li><strong>Symbolic inference ‚Üí External solver</strong></li>
  <li>Ensures logical <strong>faithfulness</strong>, <strong>robustness</strong>, and <strong>interpretability</strong>
</li>
</ul>

<h4 id="input"><strong>Input:</strong></h4>

<ul>
  <li>Natural language problem (e.g., multiple-choice or free-form question)</li>
</ul>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"Stranger Things" is a popular Netflix show.
If a Netflix show is popular, Karen will binge-watch it.
If and only if Karen binge-watches a Netflix show, she will download it.
Karen does not download "Black Mirror".
"Black Mirror" is a Netflix show.
If Karen binge-watches a Netflix show, she will share it to Lisa.

Question: Is the following statement true, false, or uncertain?  
"Black Mirror" is popular. (A) True  (B) False  (C) Uncertain
</code></pre></div></div>

<h4 id="problem-formulator-llm-generated-symbolic-form"><strong>Problem Formulator (LLM-generated symbolic form):</strong></h4>

<div class="language-prolog highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">Predicates</span><span class="o">:</span>
<span class="nv">NetflixShow</span><span class="p">(</span><span class="ss">x</span><span class="p">)</span>        <span class="o">#</span> <span class="ss">x</span> <span class="ss">is</span> <span class="ss">a</span> <span class="nv">Netflix</span> <span class="ss">show</span>
<span class="nv">Popular</span><span class="p">(</span><span class="ss">x</span><span class="p">)</span>            <span class="o">#</span> <span class="ss">x</span> <span class="ss">is</span> <span class="ss">popular</span>
<span class="nv">BingeWatch</span><span class="p">(</span><span class="ss">x</span><span class="p">,</span> <span class="ss">y</span><span class="p">)</span>      <span class="o">#</span> <span class="ss">x</span> <span class="ss">binge</span><span class="o">-</span><span class="ss">watches</span> <span class="ss">y</span>
<span class="nv">Download</span><span class="p">(</span><span class="ss">x</span><span class="p">,</span> <span class="ss">y</span><span class="p">)</span>        <span class="o">#</span> <span class="ss">x</span> <span class="ss">downloads</span> <span class="ss">y</span>
<span class="nv">Share</span><span class="p">(</span><span class="ss">x</span><span class="p">,</span> <span class="ss">y</span><span class="p">,</span> <span class="ss">z</span><span class="p">)</span>        <span class="o">#</span> <span class="ss">x</span> <span class="ss">shares</span> <span class="ss">y</span> <span class="ss">to</span> <span class="ss">z</span>

<span class="nv">Facts</span><span class="o">:</span>
<span class="nv">NetflixShow</span><span class="p">(</span><span class="ss">strangerThings</span><span class="p">)</span> <span class="err">‚àß</span> <span class="nv">Popular</span><span class="p">(</span><span class="ss">strangerThings</span><span class="p">)</span>
<span class="err">‚àÄ</span><span class="ss">x</span> <span class="p">(</span><span class="nv">NetflixShow</span><span class="p">(</span><span class="ss">x</span><span class="p">)</span> <span class="err">‚àß</span> <span class="nv">Popular</span><span class="p">(</span><span class="ss">x</span><span class="p">)</span> <span class="err">‚Üí</span> <span class="nv">BingeWatch</span><span class="p">(</span><span class="ss">karen</span><span class="p">,</span> <span class="ss">x</span><span class="p">))</span>
<span class="err">‚àÄ</span><span class="ss">x</span> <span class="p">(</span><span class="nv">NetflixShow</span><span class="p">(</span><span class="ss">x</span><span class="p">)</span> <span class="err">‚àß</span> <span class="nv">BingeWatch</span><span class="p">(</span><span class="ss">karen</span><span class="p">,</span> <span class="ss">x</span><span class="p">)</span> <span class="err">‚Üî</span> <span class="nv">Download</span><span class="p">(</span><span class="ss">karen</span><span class="p">,</span> <span class="ss">x</span><span class="p">))</span>
<span class="nv">NetflixShow</span><span class="p">(</span><span class="ss">blackMirror</span><span class="p">)</span> <span class="err">‚àß</span> <span class="err">¬¨</span><span class="nv">Download</span><span class="p">(</span><span class="ss">karen</span><span class="p">,</span> <span class="ss">blackMirror</span><span class="p">)</span>
<span class="err">‚àÄ</span><span class="ss">x</span> <span class="p">(</span><span class="nv">NetflixShow</span><span class="p">(</span><span class="ss">x</span><span class="p">)</span> <span class="err">‚àß</span> <span class="nv">BingeWatch</span><span class="p">(</span><span class="ss">karen</span><span class="p">,</span> <span class="ss">x</span><span class="p">)</span> <span class="err">‚Üí</span> <span class="nv">Share</span><span class="p">(</span><span class="ss">karen</span><span class="p">,</span> <span class="ss">x</span><span class="p">,</span> <span class="ss">lisa</span><span class="p">))</span>

<span class="nv">Query</span><span class="o">:</span>
<span class="nv">Popular</span><span class="p">(</span><span class="ss">blackMirror</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="symbolic-reasoner-output"><strong>Symbolic Reasoner Output:</strong></h4>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Result: false
</code></pre></div></div>

<h4 id="result-interpreter-output"><strong>Result Interpreter Output:</strong></h4>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Answer: (B) False
</code></pre></div></div>

<h4 id="self-refiner-if-symbolic-execution-fails"><strong>Self-Refiner (if symbolic execution fails):</strong></h4>

<ul>
  <li>Receives error from symbolic solver (e.g., ‚Äúunbound variable‚Äù)</li>
  <li>LLM revises symbolic form using in-context error correction examples</li>
  <li>Retries execution until success or max attempts</li>
</ul>

<h4 id="which-symbolic-engine-the-llms-use">Which Symbolic Engine the LLMs use?</h4>

<p>An LLM gets a prompt describing the a dedicated task.</p>

<ul>
  <li>Deductive reasoning ‚Üí Logic Programming (LP) ‚Üí Pyke</li>
  <li>First-order logic ‚Üí FOL ‚Üí Prover9</li>
  <li>Constraint satisfaction ‚Üí CSP ‚Üí python-constraint</li>
  <li>Analytical reasoning ‚Üí SAT ‚Üí Z3</li>
</ul>

<hr>

<h3 id="-algorithm-a-nesi">üß† ALGORITHM: A-NESI</h3>

<h4 id="-symbolic-prediction-vs-neural-prediction-in-a-nesi">üîç Symbolic Prediction vs Neural Prediction in A-NESI</h4>
<p><strong>A-NESI</strong> is a scalable framework for <strong>Probabilistic Neurosymbolic Learning (PNL)</strong> that combines neural perception with symbolic reasoning ‚Äî without relying on expensive exact inference.</p>
<ul>
  <li>‚úÖ <strong>Scalable Approximate Inference</strong> in polynomial time</li>
  <li>üß† <strong>Neural models</strong> for both prediction and explanation</li>
  <li>üìò <strong>Symbolic reasoning</strong> remains intact (no semantic loss)</li>
  <li>üí¨ <strong>Explainability</strong> via most probable world inference</li>
  <li>üîê <strong>Constraint satisfaction</strong> using symbolic pruning</li>
  <li>üîÑ <strong>Trained using data generated from background knowledge</strong>
</li>
</ul>

<h4 id="-core-components">üß© Core Components</h4>

<p>Given an input \(x\) (e.g., images of digits), the <strong>perception model</strong> \(f(x)\) outputs a <strong>belief</strong>:</p>

\[P = f(x)\]

<p>where \(P\) is a distribution over possible symbolic worlds \(w\) (e.g., digit pairs like (5,8)).</p>

<p>The <strong>symbolic reasoning function</strong> \(c(w)\) computes the deterministic output from a world:</p>

\[y = c(w)\]

<p>This captures prior knowledge such as digit summation or Sudoku validity rules.</p>

<p>A-NESI uses a <strong>joint factorization</strong> of the output distribution:</p>

\[q(w, y \mid P) = q(y \mid P) \cdot q(w \mid y, P)\]

<p>Here, the <strong>prediction model</strong> \(q(y \mid P)\) generates the output autoregressively, while the <strong>explanation model</strong> \(q(w \mid y, P)\) identifies the most likely symbolic world that explains the prediction.</p>

<p>To train the system, a belief prior \(p(P)\) is used to <strong>generate synthetic training data</strong>. The symbolic function \(c(w)\) is applied to each sampled world to produce the supervised output \(y = c(w)\). The prediction model is trained by minimizing the following loss:</p>

\[\mathcal{L}_{\text{Pred}} = \mathbb{E}_{(P, w)} \left[ -\log q(c(w) \mid P) \right]\]

<p>Additionally, the explanation model can be trained using a <strong>joint matching loss</strong> to align the predicted and true joint distributions:</p>

\[\mathcal{L}_{\text{Expl}} = \mathbb{E}_{(P, w)} \left[ \left( \log q(w, c(w) \mid P) - \log p(w \mid P) \right)^2 \right]\]

<table>
  <thead>
    <tr>
      <th>Aspect</th>
      <th>üßæ Symbolic Prediction</th>
      <th>üß† Neural Prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Input</strong></td>
      <td>\(P = f(x)\)</td>
      <td>\(P = f(x)\)</td>
    </tr>
    <tr>
      <td><strong>Output generation</strong></td>
      <td>\(w = \arg\max_w \, p(w \mid P), \quad y = c(w)\)</td>
      <td>\(q(y \mid P) = \prod_{i=1}^{k_Y} q(y_i \mid y_{&lt;i}, P)\)</td>
    </tr>
    <tr>
      <td><strong>Reasoning function</strong></td>
      <td>Uses symbolic reasoning \(c(w)\)</td>
      <td>No symbolic function; reasoning is learned implicitly</td>
    </tr>
    <tr>
      <td><strong>Architecture</strong></td>
      <td>Sampling + symbolic function</td>
      <td>RNN-style or Transformer-style autoregressive decoder</td>
    </tr>
    <tr>
      <td><strong>Interpretability</strong></td>
      <td>‚úÖ High: prediction traceable through \(w\) and \(c(w)\)</td>
      <td>‚ùå Low: no explicit reasoning path</td>
    </tr>
    <tr>
      <td><strong>Constraint satisfaction</strong></td>
      <td>‚úÖ Yes, via symbolic constraints \(c(w)\)</td>
      <td>‚ùå Not guaranteed (unless symbolic pruning is applied)</td>
    </tr>
    <tr>
      <td><strong>Inference speed</strong></td>
      <td>üê¢ Slower (but scalable with symbolic pruning)</td>
      <td>‚ö° Fast and parallelizable on GPU</td>
    </tr>
    <tr>
      <td><strong>Accuracy on large \(N\)</strong></td>
      <td>‚úÖ Stable even for \(N = 15\)</td>
      <td>‚ö† May degrade at large \(N\) (e.g., MNISTAdd with \(N = 15\))</td>
    </tr>
    <tr>
      <td><strong>Training role</strong></td>
      <td>Validates predictions</td>
      <td>Trains \(f(x)\) using gradients through \(q(y \mid P)\)</td>
    </tr>
    <tr>
      <td><strong>Best suited for</strong></td>
      <td>Safety-critical, explainable AI</td>
      <td>Fast inference and large-scale applications</td>
    </tr>
  </tbody>
</table>

<p><strong>Symbolic pruning</strong> in A-NESI improves inference efficiency and ensures logical correctness by eliminating invalid options during the step-by-step generation of symbolic variables. As the model generates each variable (e.g., \(w_i\)), a task-specific pruning function \(s_{y, w_{1:i-1}}(w_i)\) is applied to mask values that violate constraints defined by the symbolic function \(c(w)\). This pruning results in a modified distribution:</p>

\[q'(w_i \mid w_{1:i-1}, y, P) \propto q(w_i \mid \cdot) \cdot s_{y, w_{1:i-1}}(w_i)\]

<p>followed by renormalization:</p>

\[q'(w_i = j \mid \cdot) = \frac{q(w_i = j \mid \cdot) \cdot s(j)}{\sum_{j'} q(w_i = j' \mid \cdot) \cdot s(j')}\]

<p>For example, in MNISTAdd with target sum \(y = 13\), if \(w_1 = 9\), only \(w_2 = 4\) is valid since \(9 + 4 = 13\). All other values are pruned using:</p>

\[s_{y, w_1}(j) =
\begin{cases}
1 &amp; \text{if } w_1 + j = y \\
0 &amp; \text{otherwise}
\end{cases}\]

<p>Symbolic pruning is especially important in structured tasks like Sudoku or path planning, and the pruning function must be defined per task using logical rules or constraint checkers.</p>

<hr>

<h3 id="-algorithm-ns-vqa">üß† ALGORITHM: NS-VQA</h3>

<h1 id="ns-vqa-neuro-symbolic-visual-qa--detailed-explanation">NS-VQA (Neuro-Symbolic Visual QA) ‚Äì Detailed Explanation</h1>

<ul>
  <li>Step 1: Scene Parsing (Visual Understanding)</li>
</ul>

<p>The process begins with an input image that contains various objects. These objects are segmented using Mask R-CNN, which detects and outlines each object in the scene. Once the objects are identified, a convolutional neural network (CNN) processes these segments to extract detailed features such as shape, size, material, color, and 3D position coordinates (x, y, z). These features are organized into a structured scene representation table, where each row corresponds to one object and lists its attributes.</p>

<ul>
  <li>Step 2: Question Parsing (Program Generation)</li>
</ul>

<p>Next, the system takes a natural language question as input‚Äîsuch as ‚ÄúHow many cubes that are behind the cylinder are large?‚Äù‚Äîand converts it into a symbolic program. This conversion is performed by a GRU-based LSTM model (a type of seq2tree architecture). The model generates a series of logical operations in a domain-specific language (DSL), forming a symbolic program. For the example question, the generated steps might include filtering for cylinders, identifying objects behind them, filtering those objects for cubes, narrowing down to large ones, and finally counting them.</p>

<ul>
  <li>Step 3: Program Execution (Reasoning)</li>
</ul>

<p>The symbolic program is then executed using a Python-based symbolic executor. This executor operates on the structured scene representation to perform reasoning tasks like filtering, spatial relation extraction, and attribute comparison. Each operation manipulates the data step by step, narrowing it down based on the program logic. In the example, the system would end up with a set of large cubes behind the cylinder and return the count‚Äîsay, 3‚Äîas the final answer.</p>

<ul>
  <li>Performance Summary</li>
</ul>

<p>NS-VQA achieves remarkably high accuracy on the CLEVR dataset, outperforming most existing methods. When trained with 270 symbolic programs, it achieves 99.8% overall accuracy. It performs especially well in logically intensive tasks such as counting, comparison, and attribute querying, showing that combining neural perception with symbolic reasoning leads to powerful and interpretable AI systems.</p>

<hr>

<h3 id="-algorithm-differentiable-ilp">üß† ALGORITHM: Differentiable ILP</h3>

<p>Overview<br>
Differentiable ILP (‚àÇILP) is a neural-symbolic model that learns logical rules from data through differentiable forward chaining. It replaces discrete logical inference with neural computation and enables end-to-end learning without hand-designed rule templates.</p>

<p>Core Components</p>
<ul>
  <li>
    <p>Ground Atom Valuations:<br>
Each fact (e.g., father(alice, bob)) is assigned a continuous truth value ‚àà [0, 1], representing its current belief level. These soft valuations serve as the model‚Äôs internal working memory.</p>
  </li>
  <li>Logical Neurons:
    <ul>
      <li>Conjunction Neuron (fuzzy AND):<br>
Output = product of selected input truth values.</li>
      <li>Disjunction Neuron (fuzzy OR):<br>
Output = 1 - product of complements (i.e., fuzzy OR).<br>
Each neuron has trainable weights (via sigmoid activations) that determine which atoms participate in the logical clause.</li>
    </ul>
  </li>
  <li>
    <p>Clause Composition:<br>
The neurons form a layered structure approximating a DNF or CNF formula. Rules are represented as differentiable logic programs where each clause is a soft conjunction or disjunction of atoms.</p>
  </li>
  <li>
    <p>Forward Chaining (Iterative Reasoning):<br>
Inference is performed iteratively: at each step, the model updates the truth values of atoms using the current rules. This simulates how new facts are derived over time.</p>
  </li>
  <li>
    <p>Loss and Training:<br>
The model is trained by minimizing the cross-entropy between predicted truth values and ground-truth labels. Gradients propagate through the entire reasoning process, enabling the discovery of rule structure and content.</p>
  </li>
  <li>Predicate Invention and Recursion:<br>
Intermediate atoms (auxiliary predicates) can be created and reused across steps, enabling recursive definitions and higher expressivity in learned logic programs.</li>
</ul>

<p>Advantages</p>
<ul>
  <li>Learns interpretable symbolic rules with neural gradients</li>
  <li>Avoids reliance on rule templates or expert priors</li>
  <li>Supports recursion and predicate invention</li>
  <li>Bridges symbolic reasoning and differentiable optimization</li>
</ul>

<hr>

<h3 id="-algorithm-scallop">üß† ALGORITHM: Scallop</h3>

<p>Scallop is a neurosymbolic programming language that bridges neural perception and symbolic reasoning through differentiable logic programming. It allows users to define logical rules in a declarative language similar to Datalog and integrate them with neural network models in an end-to-end learnable system. The central idea is to separate perception and reasoning: a neural model processes raw input (such as an image or text) into intermediate symbolic representations, and a logic program applies rules over those representations to produce the final output.</p>

<p>A key feature of Scallop is that while the <strong>structure of rules</strong> can be given in the form of templates‚Äîsuch as <code class="language-plaintext highlighter-rouge">Q(X, Y) :- R(X, Z), S(Z, Y)</code>‚Äîthe <strong>actual mapping of these variables to task-specific predicates</strong> (e.g., <code class="language-plaintext highlighter-rouge">Q = ancestor</code>, <code class="language-plaintext highlighter-rouge">R = parent</code>, <code class="language-plaintext highlighter-rouge">S = ancestor</code>) is learned from data. This enables the system to generalize over symbolic patterns without requiring full supervision on internal structures. In most applications, the base predicates like <code class="language-plaintext highlighter-rouge">parent</code>, <code class="language-plaintext highlighter-rouge">friend</code>, or <code class="language-plaintext highlighter-rouge">colleague</code> are defined in advance, and Scallop searches over combinations of those to learn rules that best explain the output.</p>

<p>For example, in a knowledge reasoning task, the model may be asked to infer the <code class="language-plaintext highlighter-rouge">ancestor(X, Y)</code> relation. Given known facts like <code class="language-plaintext highlighter-rouge">parent(A, B)</code> and <code class="language-plaintext highlighter-rouge">parent(B, C)</code>, Scallop can learn to compose these into recursive rules that define ancestry. The learning process optimizes both the parameters of the neural perception module and the symbolic reasoning path using a framework based on provenance semirings, allowing gradients to flow from output supervision back through symbolic programs and into the neural components.</p>

<p>Scallop supports recursion, negation, and aggregation in its logic programs, and can be used across a range of domains including visual reasoning, program induction, planning, and reinforcement learning. By combining structured reasoning with perceptual learning in a differentiable and modular way, Scallop enables both interpretability and scalability in neurosymbolic systems.</p>

<h4 id="-example-scallop-code">üì¶ Example: Scallop Code</h4>

<pre><code class="language-scallop">// Knowledge base facts
rel is_a("giraffe", "mammal")
rel is_a("tiger", "mammal")
rel is_a("mammal", "animal")

// Knowledge base rule
rel name(a, b) :- name(a, c), is_a(c, b)

// Recognized from an image (neural model output)
rel name = {
  0.3::(1, "giraffe"),
  0.7::(1, "tiger"),
  0.9::(2, "giraffe"),
  0.1::(2, "tiger"),
}

// Aggregation query
rel num_animals(n) :- n = count(o: name(o, "animal"))
</code></pre>

<h4 id="-what-is-given-vs-what-is-trained">üîç What is Given vs. What is Trained</h4>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Given (Static) ‚úÖ</th>
      <th>Trained (Learned) üß†</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Facts (e.g., <code class="language-plaintext highlighter-rouge">is_a("tiger", "mammal")</code>)</td>
      <td>‚úÖ Provided explicitly in logic</td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Rule templates (e.g., <code class="language-plaintext highlighter-rouge">Q(X,Y) :- R(X,Z)</code>)</td>
      <td>‚úÖ Given as abstract logical structure</td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Predicate vocabulary (e.g., <code class="language-plaintext highlighter-rouge">is_a</code>, <code class="language-plaintext highlighter-rouge">name</code>)</td>
      <td>‚úÖ Declared in program or data schema</td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Neural predictions (e.g., <code class="language-plaintext highlighter-rouge">name = {...}</code>)</td>
      <td>‚ùå Produced by trained neural model</td>
      <td>‚úÖ Neural model learns from input data</td>
    </tr>
    <tr>
      <td>Rule-body mappings (e.g., <code class="language-plaintext highlighter-rouge">Q = ancestor</code>)</td>
      <td>üîÑ Can be fixed or learned (ILP-style)</td>
      <td>‚úÖ Selected based on performance from data</td>
    </tr>
    <tr>
      <td>Final prediction (e.g., <code class="language-plaintext highlighter-rouge">num_animals(n)</code>)</td>
      <td>‚ùå Derived via symbolic reasoning</td>
      <td>‚úÖ Supervised through end-to-end training</td>
    </tr>
  </tbody>
</table>

<hr>

<h3 id="-algorithm-plogicnet">üß† ALGORITHM: pLogicNet</h3>

<p><strong>pLogicNet</strong> merges symbolic logic (e.g., Markov Logic Networks) with embedding-based models (e.g., TransE, DistMult).</p>
<ul>
  <li>It uses predefined logic rules such as Composition, Inverse, Symmetric, and Subrelation.</li>
  <li>These rules are not learned but their weights are optimized using a Variational EM algorithm.</li>
  <li>
    <p>The model enhances knowledge graph reasoning by combining neural predictions with symbolic consistency.</p>
  </li>
  <li>‚úÖ Does <strong>not</strong> induce new rules; instead, it updates <strong>rule weights</strong>.</li>
  <li>‚úÖ Bridges <strong>embedding-based KGE</strong> and <strong>logical consistency</strong>.</li>
  <li>‚úÖ Resembles Datalog in how it applies symbolic rules.</li>
  <li>‚úÖ Enables interpretable reasoning while preserving neural scalability.</li>
</ul>

<h4 id="learning-procedure-variational-em">Learning Procedure (Variational EM)</h4>

<h4 id="1-e-step-expectation">1. E-Step (Expectation)</h4>
<ol>
  <li>Use a KGE (Knowledge Graph Embedding) model to infer hidden triples.</li>
  <li>Apply predefined logical rules to expand the inferred graph (via the Markov Blanket).</li>
</ol>

<h4 id="2-m-step-maximization">2. M-Step (Maximization)</h4>
<ol>
  <li>Update the weights of logical rules using observed and inferred triples.</li>
  <li>Optimize the pseudo-likelihood function for probabilistic inference.</li>
</ol>

<h4 id="example">Example</h4>

<pre><code class="language-txt">(A) Newton ‚Äî BornIn ‚Äî UK  
(B) UK ‚Äî LocatedIn ‚Äî Europe

Using a composition rule, infer:  
‚Üí Newton ‚Äî LocatedIn ‚Äî Europe

Final Score = 0.82 (KGE) + Œª √ó 1.0 (logical rule inference)
</code></pre>

<hr>

<h2 id="references">References</h2>

<ul>
  <li>
    <p>Mahaeve, DeepProbLog: Neural Probabilistic Logic Programming, 2018</p>
  </li>
  <li>
    <p>Mao, The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision, 2019</p>
  </li>
  <li>
    <p>PAN, LOGIC-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning, 2023</p>
  </li>
  <li>
    <p>Li, Scallop: A Language for Neurosymbolic Programming, 2023</p>
  </li>
  <li>
    <p>Qu et al, Probabilistic Logic Networks for Reasoning, 2019</p>
  </li>
</ul>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

<!--
    </div>
 -->
      <hr>
<!-- Footer -->    <footer class="sticky-bottom mt-5" style="border: none;border-top:0px">
      <div class="container" style="text-align: center; ">
        ¬© Copyright 2025 B. Park  . 
      </div>
    </footer>
    
    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": 0 });
    $("progress-container").css({ "padding-top": 0 });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>
  </div></body>
  
  <d-bibliography src="/assets/bibliography/all.bib">
  </d-bibliography>
  <script src="/assets/js/distillpub/overrides.js"></script>

  

  </html>
