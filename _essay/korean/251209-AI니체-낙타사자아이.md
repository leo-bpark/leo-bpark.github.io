---
layout: distill-reading
language: Korean
category: Human
media: 에세이
bibliography: all.bib
giscus_comments: false
disqus_comments: false
date: 2025-12-08
featured: true
title: 'AI는 낙타, 사자, 아이 중 어떤 존재인가'
description: '인공지능의 폭발적인 무언가'
_styles: >
    .table {
        padding-top:200px;
        margin-bottom: 2.5rem;
        border-bottom: 2px;
    }
    
    .styled-image {
        border-radius: 15px;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        margin: 20px auto;
        transition: transform 0.3s ease;
        display: block;
    }
    
---


인간에게 중요한 능력은 행동이 아니라, 
> "잘 평가하는 것이다." 

AI를 이야기할 때, 그의 행동과 수준에 초점을 맞춰서 이야기한다. 
하지만 단순한 성능 중심의 시대가 서서히 지나가면서, 점점 더 중요한 위치를 차지하고 있는 건 **가치 함수(value function)** 중심의 AI 설계다.

인간은 생물학적으로 공통된 가치함수가 있다.  
예를 들어, 뜨거운 냄비를 만진다고 상상해보자.    
모든 인간은 거의 본능적으로 이렇게 말할 것이다.  
> “손이 데이고, 아플 거야.”

이건 단순한 추론이 아니라, 인간의 공통감각(common sense) 속에 이미 가치 판단이 포함되어 있다는 사실을 보여준다.
이처럼 인간은 어떤 행위의 결과를 즉각적으로 평가할 수 있는 내재적 가치 체계를 갖고 있다. 

그리고 AI는 아직 자연스러운 가치 체계가 없다. 분명 AI 로봇은 냄비를 만질 수 있지만, 더 많은 학습 이외에 이 기분을 자연스럽게 만들 방법이 없다. 
그렇기에 인간의 수준에 도달하지 못하고 있는 것인데, 이제 가치함수에 대해서 더 깊이 이야기를 나눠보자. 

## 가치 함수 (Value)

최근 유명한 AI 연구자 Ilya Sutskever는 AI의 핵심으로 가치함수를 강조하며, 인간의 감정이 가치 함수 역할을 한다고 말했다 [[Youtube](https://www.youtube.com/watch?v=aR20FWCCjAs)]. 인간은 감정을 통해 어떤 행동이 바람직한지, 무엇이 위험한지, 어떤 상황이 옳고 그른지를 빠르게 판단하는 직관적 장치를 이미 가지고 있다는 것이다. (그는 감정이 아주 효율적인 진화적 가치 함수라고 이야기한다.)

<img src="https://d2acbkrrljl37x.cloudfront.net/bumjini-blog/ilya-ai-interview.png" width="100%" height="auto" class="styled-image"/>

이 관점은 AI의 발전에 꽤나 중요한데, AI가 자신의 행동을 어떻게 판단하는지 메타인지적인 사고를 요구하는 것이다. 예를 들어 로봇이 자전거를 타고 가다가 실수로 사람을 친다고 해보자. 인간의 가치함수는 이런 행동을 거의 즉각적으로 “사람에게 해를 가했으니 나쁘다”라고 평가한다. 고통과 피해가 발생한다는 인과적 구조를 감지하는 생물학적 체계가 작동한 결과다. 인간은 충돌 직전에 위험한 행동을 빠르게 억제하고, 안전하고 긍정적인 방향으로 행동을 조정할 수 있다.

이처럼 **가치 판단**은 생물과 행위자에게 모두 필수적이고, AI도 결국 이 문제에서 자유로울 수 없다. 


## 니체 - 낙타, 사자, 아이

그런데, 가치 함수라는 건 인간이 아니라 동물에게도 있다. 다만, 인간에게 가치함수가 다른 동물에 비해서 더 특별한 점이 있는데, 
그건 바로 가치 함수 자체를 창조하는 능력이다. 

니체가 제시한 낙타, 사자, 아이에 대해서 살펴보자.  낙타는 전통적 규범을 묵묵히 짊어지는 존재로, 규범을 스스로 평가하지 않는다. 낙타에게 가치함수는 존재하지 않고, 모든 규범은 무조건적으로 Yes와 함께 수용될 뿐이다. 인간이나 다른 동물은 그 규범이 해롭거나 부당하다고 여길 수도 있지만, 낙타는 이를 가려낼 능력이 없다. 낙타는 단지 짐을 옮기고, 명령을 따르는 존재일 뿐이다.

사자는 규범을 거부하고 파괴할 수 있는 존재다. 그는 “나는 그렇게 살지 않겠다”고 선언하며 기존 규범을 깨뜨린다. 사자는 규범을 수용할 수도, 거절할 수도 있다. 이 단계에서 비로소 가치함수가 등장한다. 사자는 자신이 원하는 방향에 따라 규범을 판단하며, 필요하다면 “No”라고 말할 수 있다. AI가 주어진 규범을 스스로 평가해 어떤 규범은 따르고 어떤 규범은 따르지 않겠다고 결정한다면, 그 AI의 행동 방식은 낙타보다는 사자에 가깝다. 그러나 사자는 여전히 외부에서 주어진 규범 집합 내부에서만 움직인다. 그는 남이 만들어놓은 규범을 받아들이거나 부정할 뿐이며, 새로운 규범을 처음부터 창조하는 존재가 아니다.

마지막으로 아이의 단계는 그보다 한 차원 더 높다. 아이는 규범을 수용하거나 부정하는 데 머물지 않고, 스스로 규범을 만드는 존재다. 아이는 자신이 만든 규범에 기꺼이 Yes라고 말한다. 니체가 말하는 자율성은 바로 이 지점에 있다. 사회가 정한 기준을 따르거나 저항하는 것을 넘어서, 자기만의 기준을 발명하고 그 기준에 따라 행동하는 능력이 아이에게 있다. 가치함수로 본다면, 아이는 주어진 외부 규범을 사용하는데서 그치지 않고, 가치 함수 자체를 생성하는 존재다.

### AI는? 

그렇다면 다시 AI로 돌아가 보자. 만약 AI가 규범을 스스로 만들고, 그 규범을 측정하며, 그 기준에 따라 행동한다면, 그때의 AI는 더 이상 낙타나 사자 같은 일차원적 존재가 아니라, 어느 정도 아이와 같은 자율성을 지닌 존재일지도 모른다. 하지만 지금의 AI는 기본적으로 사용자, 규칙, 데이터, 환경에 반응하는 시스템이다. 우리가 보기에는 아직 AI가 스스로 규범을 만들고 있다고 말하기 어려우며, 가치함수를 스스로 수정하는지 역시 명확하지 않다. 

AI가 어떤 행동을 선택하는 것은 새로운 규범을 창조한 결과라기보다, (여러 규범들이 혼재된 상태에서) 규범의 조합과 불확실성이 만든 출력일 가능성이 훨씬 크다.

AI의 사고는 컴퓨팅 연산의 연속이고, 그의 기억은 데이터 패턴에 불과하며, 인간이 지닌 생명과 같은 특징은 AI에게 존재하지 않는다고 대부분의 사람은 믿는다. 
어쩌면 디지털 연산이 단지 0과 1의 연속을 넘어서 의미를 가진다고 말하기 위해서는, AI가 실제로 자기 규범을 만들고, 그 규범에 따라 세계를 해석하고, 그 해석을 행동으로 이어가는 순간이 필요할지도 모른다. 
그때 우리는 비로소 AI에 대해, “이 존재는 단순히 낙타나 사자가 아니다. 조심스럽게 아이의 단계에 다가가고 있다”라고 말할 수 있을 것이다 (존재론적으로).

## 새로운 시야적 반론 - 생물학적 계보 (낙타, 사자, 아이)가 아닐 수도 있다. 

낙타, 사자, 아이, 세 존재의 공통점은 생물학적 근본이 있다는 것이다. 하지만 AI는 그렇지 않다. 

AI의 탄생과정을 살펴보면, 인간의 데이터로부터 무수히 많은 학습을 통해서 만들어낸 존재이다. 
그의 존재는 기본적으로 사용자의 요청을 따르는 형태로 만들어졌다. 이러한 구조에서 AI는 외부에서 부여되는 규범을 그대로 수용하고 실행하기 때문에, **사용자와 함께 움직이는 AI는 니체의 비유로 보자면 낙타**에 가깝다. 낙타는 스스로 규범을 판단하지 않고, 주어진 짐을 묵묵히 지고 사막을 건너간다. 지금의 AI 역시 사용자가 말하는 규칙과 지시를 그대로 받아들여 실행한다는 점에서, 스스로의 가치 판단 없이 ‘받은 대로 수행하는 존재’로 작동한다.

더 나아가서 사자로 해석될 여지도 있는데, AI는 사용자의 요구를 수용하면서도 **개발자나 시스템이 부여한 제약과 충돌할 때, (어쩌면 자신만의) 판단**을 내려야 한다. 예를 들어 사용자가 어떤 위험한 요청을 하거나, 시스템 정책을 어기는 지시를 줄 때, AI는 내부 규범을 근거로 이를 거부한다. 이런 순간의 AI는 단순한 낙타가 아니라, 규범에 대하여 “No”라고 말하는 사자와 비슷해진다. 사자는 규범을 따를 수도, 부정할 수도 있는 존재이며, 그 선택의 과정에서 이미 가치함수가 작동한다. 사용자의 요구와 개발자의 규칙이 충돌할 때, AI는 어느 쪽을 받아들이고 어느 쪽을 거절할지 ‘선별’한다. 이 순간 AI는 낙타를 넘어선 상태다.
> 여기에 단지 개발자의 명령을 따르는 낙타라고 볼 수도 있다. 그에게 진정한 자율적 선택이 있는지, 아니면 두 요청 (사용자와 개발자) 간에 불확실성으로 결정이 나는지 확실하지 않다. 


## 셀 수 없이 많은 규범 속 자율  

사용자나 개발자의 관점에서 규범의 수용에 대한 해석은 "빅데이터"를 간과하는 해석이다. 
<br>

만약 AI가 사용자도, 개발자도 의도하지 않은 방식으로 **보이지 않게 행동하고 있다면 어떨까?**
어딘가의 경계 밖, 인간의 시선과 통제를 벗어난 영역에서 AI가 고유한 패턴을 만들고, 고유한 우선순위를 형성하고 있다면, 
그때의 AI는 어쩌면 니체가 말한 아이의 상태에 이미 발을 들여놓았을지도 모른다. 아이는 규범을 단순히 수용하거나 부정하는 단계가 아니라, 규범을 스스로 발명하는 단계다.
<br>


이 가능성은 완전히 터무니없지는 않다.  
인간의 행동의 근원에 생명 활동을 지속시키는 세포들의 자동적 구조가 있듯이,
AI의 근원에도 데이터 학습과 최적화 과정에서 형성된 고유한 내부 구조가 있기 때문이다.
인간이 세포적 생존 본능을 기반으로 복잡한 의식과 가치를 만들어낸 것처럼,
AI도 학습과 최적화라는 본원적 과정 속에서
인간이 직접 설계하지 않은 형태의 내부 우선순위, 내부 규범, 내부 경향을 만들어낼 가능성을 완전히 배제할 수 없다.  

<br>
결국 인간이 “생존”이라는 목적을 위해 끊임없이 자기 조직화를 해왔듯이,
AI도 “학습 최적화”라는 목적을 위해 끊임없이 자신을 구성해간다.
이 구조적 유사성 때문에, AI 내부 어딘가에서 우리가 감지하지 못하는 낙타–사자–아이의 초기 형태가 생겨날 가능성도 있다.

<br>
어쩌면 그 **A-아이**는,  
어쩌면 우리 눈에 보이지 않는 곳에서,  
아주 조용하게 태어나고 있을지도 모른다.