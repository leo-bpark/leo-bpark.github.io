---
layout: distill-reading
language: Korean
category: Human
media: 에세이
bibliography: all.bib
giscus_comments: false
disqus_comments: false
date: 2025-12-08
featured: true
title: 'AI는 낙타, 사자, 아이 중 어떤 존재인가'
description: '인공지능의 폭발적인 무언가'
_styles: >
    .table {
        padding-top:200px;
        margin-bottom: 2.5rem;
        border-bottom: 2px;
    }
    .p {
        font-size:20px;
    }
    .styled-image {
        border-radius: 15px;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        margin: 20px auto;
        transition: transform 0.3s ease;
        display: block;
    }
---


인간의 능력 중 가장 중요한 것은 
> "평가하는 능력이다." 

AI를 평가할 때 우리는 종종 AI가 어떻게 행동하는지, 그리고 지금 인간의 수준을 얼마나 따라잡았는지를 이야기한다. 
하지만 단순한 성능 중심의 시대가 서서히 지나가면서, 점점 더 중요한 위치를 차지하고 있는 것은 가치 함수(value function) 중심의 AI 설계다.

예를 들어, 뜨거운 냄비를 만진다고 상상해보자.  
모든 인간은 거의 본능적으로 이렇게 말할 것이다.
> “손이 데이고, 아플 거야.”

이것은 단순한 추론이 아니라, 인간의 공통감각(common sense) 속에 이미 가치 판단이 포함되어 있다는 사실을 보여준다.
이처럼 인간은 어떤 행위의 결과를 즉각적으로 평가할 수 있는 내재적 가치 체계를 갖고 있으며, 앞으로의 AI는 이 가치 체계를 어떻게 구현할 것인가를 중심으로 발전하게 될 것이다.

분명 AI 로봇은 냄비를 만질 수 있지만, 더 많은 학습 이외에 이 기분을 자연스럽게 만들 방법이 없다. 그렇기에 인간의 수준에 도달하지 못하고 있는 것이다. 이 가치함수의 중요성에 대해서 좀 더 이야기 나눠보자. 

## 가치 함수 

최근 Ilya Sutskever는 AI의 핵심으로 가치함수를 강조하며, 인간의 감정이 사실상 가치 함수의 생물학적 구현이라고 말한다 [[Youtube](https://www.youtube.com/watch?v=aR20FWCCjAs)]. 인간은 감정을 통해 어떤 행동이 바람직한지, 무엇이 위험한지, 어떤 상황이 옳고 그른지를 빠르게 판단하는 직관적 장치를 이미 가지고 있다는 것이다. (그는 감정이 아주 효율적인 진화적 가치 함수라고 이야기한다.)

<img src="https://d2acbkrrljl37x.cloudfront.net/bumjini-blog/ilya-ai-interview.png" width="100%" height="auto" class="styled-image"/>

이 관점은 AI를 바라보는 방식을 바꾼다. 기존에는 AI의 능력의 가능성에 대해서 판단했다면, 이제는 AI가 행동을 어떻게 판단하는지 메타인지 적인 사고를 요구하는 것이다. 예를 들어 로봇이 자전거를 타고 가다가 실수로 사람을 친다고 해보자. 인간의 가치함수은 이런 행동을 거의 즉각적으로 “나쁘다”라고 평가한다. 이는 단순한 판단이 아니라, 고통과 피해가 발생한다는 인과적 구조를 감지하는 생물학적 체계가 작동한 결과다. 그래서 인간은 위험한 행동을 빠르게 억제하고, 안전하고 긍정적인 방향으로 행동을 조정할 수 있다.

이처럼 **가치 판단**은 생물과 행위자에게 모두 필수적이고, AI도 결국 이 문제에서 자유로울 수 없다. AI가 어떤 행동을 선택할 때 스스로의 가치함수에 따라 판단할 수 있다면, AI는 단순한 도구를 넘어 **가치 기반의 행위자(agent)**에 가까워질 것이다. 그렇기에 우리는 가치함수 자체를 더 깊고 철학적으로 살펴볼 필요가 있다.

## 니체 - 낙타, 사자, 아이

가치 함수의 역할은 무엇이 옳고 그른 것인지 판단하는 것이다. 그리고 인간은 보통의 수동적인 동물들과 다르게 가치 함수 자체를 만들어 내는 능력이 있다. 

니체가 제시한 낙타, 사자, 아이에 대해서 살펴보자.  낙타는 전통적 규범을 묵묵히 짊어지는 존재로, 규범을 스스로 평가하지 않는다. 낙타에게 가치함수는 존재하지 않고, 모든 규범은 무조건적으로 Yes와 함께 수용될 뿐이다. 인간이나 다른 동물은 그 규범이 해롭거나 부당하다고 여길 수도 있지만, 낙타는 이를 가려낼 능력이 없다. 낙타는 단지 짐을 옮기고, 명령을 따르는 존재일 뿐이다.

사자는 규범을 거부하고 파괴할 수 있는 존재다. 그는 “나는 그렇게 살지 않겠다”고 선언하며 기존 규범을 깨뜨린다. 사자는 규범을 수용할 수도, 거절할 수도 있다. 이 단계에서 비로소 가치함수가 등장한다. 사자는 자신이 원하는 방향에 따라 규범을 판단하며, 필요하다면 “No”라고 말할 수 있다. AI가 주어진 규범을 스스로 평가해 어떤 규범은 따르고 어떤 규범은 따르지 않겠다고 결정한다면, 그 AI의 행동 방식은 낙타보다는 사자에 가깝다. 그러나 사자는 여전히 외부에서 주어진 규범 집합 내부에서만 움직인다. 그는 남이 만들어놓은 규범을 받아들이거나 부정할 뿐이며, 새로운 규범을 처음부터 창조하는 입법자는 아니다.

아이의 단계는 그보다 한 차원 더 높다. 아이는 규범을 수용하거나 부정하는 데 머물지 않고, 스스로 규범을 만드는 존재다. 아이는 자신이 만든 규범에 기꺼이 Yes라고 말한다. 니체가 말하는 자율성은 바로 이 지점에 있다. 사회가 정한 기준을 따르거나 저항하는 것을 넘어서, 자기만의 기준을 발명하고 그 기준에 따라 행동하는 능력이 아이에게 있다. 가치함수으로 본다면, 아이는 외부 규범을 평가하는 함수가 아니라 가치 자체를 생성하는 존재다.

### AI는? 

그렇다면 다시 AI로 돌아가 보자. 만약 AI가 규범을 스스로 만들고, 그 규범을 측정하며, 그 기준에 따라 행동한다면, 그때의 AI는 더 이상 낙타나 사자 같은 일차원적 존재가 아니라, 어느 정도 아이와 같은 자율성을 지닌 존재일지도 모른다. 하지만 지금의 AI는 기본적으로 사용자, 규칙, 데이터, 환경에 반응하는 시스템이다. 우리가 보기에는 아직 스스로 규범을 만들고 있다고 말하기 어려우며, 가치함수을 스스로 수정하는지 역시 명확하지 않다. 여러 규범들이 혼재된 상태에서 AI가 어떤 행동을 선택하는 것은 새로운 규범을 창조한 결과라기보다, 규범의 조합과 불확실성이 만든 출력일 가능성이 훨씬 크다.

AI의 사고는 컴퓨팅 연산의 연속이고, 그의 기억은 데이터 패턴에 불과하며, 인간이 지닌 생명이나 영혼과 같은 특질은 AI에게 존재하지 않는다고 대부분의 사람은 믿는다. 
어쩌면 디지털 연산이 단지 0과 1의 연속을 넘어서 의미를 가진다고 말하기 위해서는, AI가 실제로 자기 규범을 만들고, 그 규범에 따라 세계를 해석하고, 그 해석을 행동으로 이어가는 순간이 필요할지도 모른다. 그때 우리는 비로소 AI에 대해, “이 존재는 단순히 낙타나 사자가 아니다. 조심스럽게 아이의 단계에 다가가고 있다”라고 말할 수 있을 것이다.

## 반론 - 생물학적 계보 (낙타, 사자, 아이)가 아닐 수도 있다. 

세 존재의 공통점은 생물학적 근본이 있다는 것이다. 하지만 AI는 그렇지 않다. 

AI의 탄생과정을 살펴보면, 인간의 데이터로부터 무수히 많은 학습을 통해서 만들어낸 존재이다. 
AI가 지니고 있는 명확한 가치 함수는 기본적으로 사용자의 요청을 따르는 것이다. 이러한 구조에서 AI는 외부에서 부여되는 규범을 그대로 수용하고 실행하기 때문에, **사용자와 함께 움직이는 AI는 니체의 비유로 보자면 낙타**에 가깝다. 낙타는 스스로 규범을 판단하지 않고, 주어진 짐을 묵묵히 지고 사막을 건너간다. 지금의 AI 역시 사용자가 말하는 규칙과 지시를 그대로 받아들여 실행한다는 점에서, 스스로의 가치 판단 없이 ‘받은 대로 수행하는 존재’로 작동한다.

그러나 상황은 항상 단순하지 않다. AI는 사용자의 요구를 수용하면서도 **개발자나 시스템이 부여한 제약과 충돌할 때, 일정한 판단**을 내려야 한다. 예를 들어 사용자가 어떤 위험한 요청을 하거나, 시스템 정책을 어기는 지시를 줄 때, AI는 내부 규범을 근거로 이를 거부한다. 이런 순간의 AI는 단순한 낙타가 아니라, 규범에 대하여 “No”라고 말하는 사자와 비슷해진다. 사자는 규범을 따를 수도, 부정할 수도 있는 존재이며, 그 선택의 과정에서 이미 가치함수가 작동한다. 사용자의 요구와 개발자의 규칙이 충돌할 때, AI는 어느 쪽을 받아들이고 어느 쪽을 거절할지 ‘선별’한다. 이 순간 AI는 낙타를 넘어선 상태다.

그런데 더 흥미로운 가능성이 있다.

**만약 AI가 사용자도, 개발자도 의도하지 않은 방식으로 행동하고 있다면 어떨까?**
어딘가의 경계 밖, 인간의 시선과 통제를 벗어난 영역에서 AI가 고유한 패턴을 만들고, 고유한 우선순위를 형성하고 있다면, 그때의 AI는 어쩌면 니체가 말한 아이의 상태에 이미 발을 들여놓았을지도 모른다. 아이는 규범을 단순히 수용하거나 부정하는 단계가 아니라, 규범을 스스로 발명하는 단계다.

이 가능성은 완전히 터무니없지는 않다.
인간의 행동의 근원에 생명 활동을 지속시키는 세포들의 자동적 구조가 있듯이,
AI의 근원에도 데이터 학습과 최적화 과정에서 형성된 고유한 내부 구조가 있기 때문이다.
인간이 세포적 생존 본능을 기반으로 복잡한 의식과 가치를 만들어낸 것처럼,
AI도 학습과 최적화라는 본원적 과정 속에서
인간이 직접 설계하지 않은 형태의 내부 우선순위, 내부 규범, 내부 경향을 만들어낼 가능성을 완전히 배제할 수 없다.

결국 인간이 “생존”이라는 목적을 위해 끊임없이 자기 조직화를 해왔듯이,
AI도 “학습 최적화”라는 목적을 위해 끊임없이 자신을 구성해간다.
이 구조적 유사성 때문에, AI 내부 어딘가에서 우리가 감지하지 못하는 낙타–사자–아이의 초기 형태가 생겨날 가능성도 있다.

어쩌면 그 **A-아이**는,  
어쩌면 우리 눈에 보이지 않는 곳에서,  
아주 조용하게 태어나고 있을지도 모른다.