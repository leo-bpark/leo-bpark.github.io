---
layout: workin-progress
bibliography: all.bib
giscus_comments: false
disqus_comments: false
date: 2025-02-10
featured: true
img: assets/img/feigenbaum.png
title: 'Work-in-Porgress'
category: 'AI'
description: 'Last Updated: 25/12/27'
_styles: >
    table {
        padding-top: 200px;
        margin-bottom: 2.5rem;
        border-bottom: 2px;
        width: 120%;
        table-layout: fixed;
    }
    .p {
        font-size: 20px;
        font-weight: 250;
    }
    .styled-image {
        border-radius: 15px;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        margin: 20px auto;
        transition: transform 0.3s ease;
        display: block;
    }
    .styled-image:hover {
        transform: scale(1.2);
    }
    td, th {
        font-size: 1.10rem;
        font-family: 'Times New Roman', Times, serif;
    }
---
```json
{
  "projects": [
    {
      "id": "IPJ",
      "title": "Incomplete Prompt Jailbreak",
      "highlight-color": "#5555af",
      "progress": 60,
      "status": "in-progress",
      "research-question": "How can incomplete prompts be used to jailbreak language models?",
      "main-contribution": [
        "eee",
        "Novel approach to understanding **prompt injection vulnerabilities**"
      ],
      "impact": "High - addresses critical security concerns in LLM deployment",
      "highly-related-work": [
        {
          "type": "paper",
          "title": "Related Paper Title 1",
          "authors": [],
          "year": null,
          "url": ""
        },
        {
          "type": "paper",
          "title": "Related Paper Title 2",
          "authors": [],
          "year": null,
          "url": ""
        }
      ],
      "links": [
        {
          "type": "github",
          "label": "GitHub Repository",
          "url": "https://github.com/yourusername/project"
        },
        {
          "type": "overleaf",
          "label": "Overleaf Document",
          "url": "https://www.overleaf.com/project/yourproject"
        }
      ],
      "tags": ["security", "jailbreaking", "prompt-engineering"],
      "start-date": "2025-01-01",
      "last-updated": "2025-02-10"
    },
  
    {
      "id": "Sparse Prober",
      "highlight-color": "#00aa00",
      "title": "Sparse Prober",
      "progress": 60,
      "status": "in-progress",
      "research-question": "How can incomplete prompts be used to jailbreak language models?",
      "main-contribution": "Novel approach to understanding prompt injection vulnerabilities",
      "impact": "High - addresses critical security concerns in LLM deployment",
      "highly-related-work": [
        {
          "type": "paper",
          "title": "Related Paper Title 1",
          "authors": [],
          "year": null,
          "url": ""
        },
        {
          "type": "paper",
          "title": "Related Paper Title 2",
          "authors": [],
          "year": null,
          "url": ""
        }
      ],
      "links": [
        {
          "type": "github",
          "label": "GitHub Repository",
          "url": "https://github.com/yourusername/project"
        },
        {
          "type": "overleaf",
          "label": "Overleaf Document",
          "url": "https://www.overleaf.com/project/yourproject"
        }
      ],
      "tags": ["security", "jailbreaking", "prompt-engineering"],
      "start-date": "2025-01-01",
      "last-updated": "2025-02-10"
    },



    {
      "id": "NMR",
      "title": "Deduction Conflict",
      "highlight-color": "#aa0000",
      "progress": 60,
      "status": "in-progress",
      "research-question": "How can incomplete prompts be used to jailbreak language models?",
      "main-contribution": "Novel approach to understanding prompt injection vulnerabilities",
      "impact": "High - addresses critical security concerns in LLM deployment",
      "highly-related-work": [
        {
          "type": "paper",
          "title": "Related Paper Title 1",
          "authors": [],
          "year": null,
          "url": ""
        },
        {
          "type": "paper",
          "title": "Related Paper Title 2",
          "authors": [],
          "year": null,
          "url": ""
        }
      ],
      "links": [
        {
          "type": "github",
          "label": "GitHub Repository",
          "url": "https://github.com/yourusername/project"
        },
        {
          "type": "overleaf",
          "label": "Overleaf Document",
          "url": "https://www.overleaf.com/project/yourproject"
        }
      ],
      "tags": ["security", "jailbreaking", "prompt-engineering"],
      "start-date": "2025-01-01",
      "last-updated": "2025-02-10"
    },


  {
      "id": "Kolmar",
      "title": "Material Representation",
      "highlight-color": "#0000a0",
      "progress": 60,
      "status": "in-progress",
      "research-question": "물성 예측에 대한 인코딩 학습",
      "main-contribution": [
        "트랜스포머 기반의 물성 예측 학습",
        "실제 데이터 기반의 학습: 트랜스포머 기반의 물성 예측 학습"
      ],
      "impact": "High - addresses critical security concerns in LLM deployment",
      "highly-related-work": [
        {
          "type": "paper",
          "title": "Related Paper Title 1",
          "authors": [],
          "year": null,
          "url": ""
        },
        {
          "type": "paper",
          "title": "Related Paper Title 2",
          "authors": [],
          "year": null,
          "url": ""
        }
      ],
      "links": [
        {
          "type": "github",
          "label": "GitHub Repository",
          "url": "https://github.com/yourusername/project"
        },
        {
          "type": "submission",
          "label": "Overleaf Document",
          "url": "https://www.overleaf.com/project/yourproject"
        }
      ],
      "tags": ["security", "jailbreaking", "prompt-engineering"],
      "start-date": "2025-01-01",
      "last-updated": "2025-02-10"
    }


  ]
}
```

## Work-in-Progress 

