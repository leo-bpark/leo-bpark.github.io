---
layout: distill-reading
language: English
category: Logic
media: Study
bibliography: all.bib
giscus_comments: false
disqus_comments: false
date: 2026-01-02
featured: true
title: '<strong>Working/Persistent 메모리 and Instances/Rules Knowledge  </strong>'
description: '지식을 다루는 도구와 지식의 형태는 일치하지 않는다. 2x2 부조화'
---


LLM에서 규칙이 어떻게 저장되는지를 연구한다는 것은, LLM 자체와 규칙이라는 대상 모두를 동시에 이해해야 하는 문제다.

지식의 저장 방식은 크게 두 가지로 나눌 수 있다. 하나는 long-term memory로, 오랜 기간 유지되며 반복적으로 사용되는 기억이다. 다른 하나는 short-term memory로, 일시적으로 유지되었다가 사라지는 기억이다. LLM의 관점에서 보면, long-term memory는 모델 파라미터에 저장된 지식에 해당하고, short-term memory는 입력 프롬프트를 통해 주어지는 정보로 볼 수 있다. 최근의 외부 메모리 구조는 short-term에 존재하던 정보를 장기적으로 보존 가능하게 만든다는 점에서, short-term을 long-term으로 전환하는 과정으로 해석할 수 있다.

지식의 형태 역시 두 가지로 나눌 수 있다. 하나는 규칙이고, 다른 하나는 **예시(instance)**다. 규칙은 일반적으로 알려진 사실이거나 평균적으로 자주 등장하는 지식의 형태다. 또한 인과적 구조를 가지며, 조건에 따라 반복적으로 적용될 수 있는 특징을 가진다. 반면 예시 기반 지식은 특정 상황이나 객체 간의 관계를 기술하는 데 강점이 있지만, 동일한 예시가 다른 상황에서도 그대로 통용된다고 보기는 어렵다.

인간의 뇌를 살펴보면, 우리는 지식의 형태에 따라 그것이 어디에 저장되어 있는지를 명확히 알지 못한다. 더 나아가, 이러한 지식들이 서로 어떤 방식으로 연결되어 추론을 이끄는지 이해하는 것도 쉽지 않다.

LLM에서도 유사한 어려움이 존재한다. 일반적으로 long-term에 저장된 지식은 short-term 정보에 비해 관계 구조를 파악하고 해석하기가 더 어렵다. 동일한 지식 형태가 long-term과 short-term에 나뉘어 존재하는 경우라면, 두 저장 방식 간의 관계를 비교적 수월하게 분석할 수 있다. 그러나 long-term에 규칙이 저장되고 short-term에 예시가 주어지는 경우, 혹은 그 반대처럼 완전히 교차된 형태에서는, 서로 다른 유형의 지식이 서로 다른 저장소에 존재하게 된다. 이 경우 분석 난이도는 급격히 상승한다.

여기에 지식 간 conflict까지 고려하면 문제는 더욱 복잡해진다. 지식의 형태(규칙/예시)와 저장 방식(long/short)이 이루는 2×2 공간 전반에서 충돌이 발생할 수 있기 때문이다. 하지만 우리는 아직 어떤 지식이 어떤 방식으로 저장되는지조차 명확히 이해하지 못하고 있다. 이런 상황에서 서로 다른 도메인에 걸친 conflict를 정의하고 분석하려는 시도는, 상당한 리스크를 내포한 연구라고 볼 수 있다.


> 차라리 뉴런에도 **타입**이 존재하면 좋겠다는 생각이 든다.  
> 논리적 형태의 연산을 담당하는 뉴런, 그리고 예시를 암기하는 뉴런처럼 말이다.  
>  
> 마치 지도 위에 나라와 수도가 구분되어 표시되듯, 뉴런의 종류가 명확히 나뉜다면  
> 예시들은 자연스럽게 ‘수도’에 해당하는 뉴런을 주로 활성화하려 할 것이다.  
> 그런데 만약 그 대상이 수도가 아니라 광역시라면, 혹은 하나의 주(state)라면  
> 우리는 어떻게 이해해야 할까?  
>  
> 규칙이라는 것은 단일한 형태의 뉴런에만 대응되기보다는,  
> 다양한 유형의 뉴런들을 통해 구현될 가능성이 크다.  
> 그리고 그 주들 사이에는 분명 상호작용이 존재할 수 있으며,  
> 동시에 각 주는 다시 예시—이를테면 위성 도시들과도—관계를 맺게 된다.  
>  
> 그렇다면 결국 규칙이라는 것은  
> 단순한 조건의 집합이 아니라,  
> 그 자체로 하나의 **세계를 이루는 구조**가 아닐까.

--- 



규칙을 학습한다는 것은 꽤나 심오한 일이다. 
두 가지 개념을 만들어서 연결하는 과정이고, 단순하게 아는 것을 연결하는 것을 넘어서, 
안다는 것이 무엇인지도 정의해야 하기 때문이다. 

최종적으로 LLM이나 인간에 맞춰서 생각하면 다음 표를 생각할 수 있다. 

|            > Data <br> Memorization Type   |  **Rule Format** <br> (Like Reading a Book) | **Instance Format** <br> (Experiencing Instances) | 
| **Working Memory**<br> (ICL, Test-Time Memory ) |   규칙을 보고 쓴다. | 예시를 보고 일반화 한다. 
| **Persistent Memory** <br> (Tuning, Weight)     |  규칙을 암기한다. | 예시에서 규칙을 기록한다.

총 4가지 영역에 대해서 주어진 데이터에 대해서 서로 상호작용이 되는지, 혹은 어떻게 관계를 맺고 있는지 확실하지 않다. 
가령, 주어진 instruction에 규칙이 있는 것은, 예시에 대한 일반화가 되는 것인지, 
아니면 반대로 예시를 많이 넣으면 규칙으로 작성하는 것인지 알 수 없다. 

이는 한편으로 뇌에 존재하는 엔그렘 발화에 대한 관점을 상기시킨다. 
만일 파라미터에 녹아 있는 규칙이 있다면, 규칙을 적용해야 하는 예시들이 주어졌을 때, 해당 규칙을 사용할 때 켜지는 뉴런이 발화하여 
서로 관계 맺는 것을 도와주는 것이다. 즉 뉴런의 동시 발화적인 측면에 대해서 생각할 부분은 많다. 

다음 전이를 생각해보자. 

| 입력 | 기대 기능 | 일반화 가능성   | 
| --- | ------- | ------ | 
| **WM**-<br>RF  | **WM**-<br>IF  | 입력으로 주어지는 일반 규칙에 대해서, 예시들에 대해서 적용하는 것은 가능할 것으로 보인다. 
| **WM**-<br>IF  | **WM**-<br>RF  | 입력으로 주어지는 예시들에 대해서 일반화된 규칙을 이끌어 내는 것은 가능할 것으로 보인다. 
| **PM**-<br>RF  | **PM**-<br>IF  | 파라미터에 저장된 규칙은, 인스턴스와 어떤 관계가 있는지 아는 것은 어렵다. 
| **PM**-<br>IF  | **PM**-<br>RF  | 인스턴스들에 대해서 활성화 되는 뉴런에 규칙의 발화는 어떤 영향을 주는지 이해하는 것은 좀 더 직관적이다.  
| **WM**     | **PM**     | 작업기억으로 주어지는 것이 어떤 뉴런에 쓰여야 하는지 확실하지 않는다. 인간의 뇌는 어디에 무엇을 넣을지 잘 관리하는가? 컴퓨터처럼? 
| **PM**     | **WM**     | 기억 속에 저장된 규칙이 있을 때, 이 규칙이 Working 상태로 넘어오는 것은 쉬울 것으로 보인다. 


난제: 
1. 규칙에 대한 표현은 다양하게 적힐 수 있다. 서로 다른 형태의 규칙 표현들은, 각기 다르게 처리되어야 하는가? 
2. 예시들은 충분히 많이 있어야 공통점이 보인다. 이 때 보이는 공통점은 규칙들에 대한 일반 표현으로 볼 수 있는가? 