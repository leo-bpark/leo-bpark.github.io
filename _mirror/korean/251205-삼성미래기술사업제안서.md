---
layout: distill-reading
language: Korean
category: AI
media: 제안서
bibliography: all.bib
giscus_comments: false
disqus_comments: false
date: 2025-12-05
featured: true
title: '삼성미래기술사업 제안서'
description: '심볼해석-추론설명 네트워크'
_styles: >
    .table {
        padding-top:200px;
        margin-bottom: 2.5rem;
        border-bottom: 2px;
    }
    .p {
        font-size:20px;
    }
    .styled-image {
        border-radius: 15px;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        margin: 20px auto;
        transition: transform 0.3s ease;
        display: block;
    }
---

## 문제 제기 (Problem Statement)

대규모 언어모델(LLM)은 다양한 지적 과제를 수행하며 인공지능의 새로운 가능성을 열었지만, 여전히 법률 판단, 복잡한 상식 추론, 고정밀 의사결정과 같이 높은 신뢰성이 요구되는 영역에서는 근본적 한계를 드러내고 있다. 대표적으로 **헬루시네이션(hallucination)**, **지식 충돌(knowledge conflict)**, **비일관적 추론 경로(inconsistent reasoning paths)** 등은 LLM이 내린 결론의 타당성을 평가하기 어렵게 만들며, 실제 활용에 큰 제약을 준다. 정보 보강(RAG)이나 모델·데이터 스케일링과 같은 기존 접근은 이러한 구조적 문제를 해결하지 못하고 있으며, 특히 법률·의료처럼 결과의 정확성과 설명 가능성이 필수적인 분야에서는 한계가 더욱 뚜렷하다.

반면 인간의 추론은 다양한 정보와 규칙을 심볼(symbol) 단위로 해석하고, 그 과정의 적절성을 가치함수(value function)를 통해 평가함으로써 안정적이고 일관된 결론을 도출한다. 인간은 단순히 지식을 나열하는 것이 아니라, 서로 다른 추론 경로를 종합해 합리성을 판단하며 최종 결론에 이른다. 이러한 구조는 복잡한 문제에서도 강건한 추론을 가능하게 하지만, 현존 LLM에는 이러한 심볼 기반 해석(symbolic interpretation)과 추론 적절성 평가(reasoning validity evaluation)가 거의 구현되어 있지 않다.

1. 분산표현 기반 LLM은 심볼기반 알고리즘(symbolic algorithms)의 장점을 효율적으로 사용하지 못한다.  
2. 심볼기반 알고리즘은 확장성(scalability)에 실패하였다.  

본 연구는 이러한 한계를 극복하기 위해, 인간의 심볼적 추론 방식을 통합한 **SIREN(Symbol Interpretation and Reasoning Explanation Network)**을 제안한다. SIREN은 다양한 추론 경로에서 생성되는 정보를 심볼 수준(symbol-level)에서 해석하고, 그 과정의 적절성과 일관성을 평가함으로써 기존 LLM이 제공하지 못한 설명 가능하고 강건한 고차 추론 능력을 구현하고자 한다.


## 한계점 분석과 연구 동기 (Analysis of Limitations and Research Motivation)

LLM은 분산표현(distributed representation)에 기반해 문맥 내 학습(in-context learning), RAG(정보 보강), ROME 기반 지식 편집(ROM-based knowledge editing), 메모리 업데이트, 제약 생성(constrained decoding), 테스트타임 연산(test-time compute) 확장, KV 캐시(KV cache) 조정, 토큰 정제 등 다양한 방식으로 추론 안정성을 강화하려는 시도가 이루어져 왔다. 또한 기계적 해석(mechanistic interpretability)을 통해 내부 뉴런과 회로를 분석해 의미 구조를 제어하려는 연구도 활발하다. 그러나 이러한 방법들은 모두 분산표현의 의미적 모호성(semantic ambiguity) 때문에 지식 충돌(knowledge conflict)과 헬루시네이션(hallucination)을 구조적으로 해결하지 못한다. 벡터 공간의 중첩(superposition) 특성은 개념 경계를 흐리게 하며, 추론 과정의 정당성 평가(validity checking)도 어렵게 만든다. 따라서 LLM 내부 표현 조정만으로는 일관성(consistency), 설명 가능성(explainability), 의미 분리(separability)를 달성하기 어렵다는 교훈을 준다.

한편, 심볼 기반 추론은 사실관리시스템(TMS: Truth Maintenance System), 디폴트 논리(Default Logic), 철회 논리(Defeasible Logic), 비단조추론(non-monotonic reasoning), 논증 프레임워크(Argumentation Framework) 등으로 발전하며, 현실 세계의 불확실성·충돌·정보 수정 문제를 정교하게 다루기 위해 확장되었다. 이들은 증거 간 공격(attack)·지지(support) 관계를 명확히 모델링하여 법률·의료 같은 고정밀 추론 환경에 적합한 구조를 제공한다. 그러나 심볼 기반 방식은 계산 복잡도가 높아 대규모 환경에 적용하기 어렵고, 자연어를 직접 다루지 못하며, 분산표현 기반 LLM과 정렬(alignment)에도 한계를 가진다. 즉, 심볼 기반 접근은 해석 가능성(explainability)은 높지만 확장성(scalability)은 부족하고, 반면 LLM은 확장성은 높지만 추론 통제(reasoning control)가 어렵다는 구조적 단절(structural gap)이 존재한다.

이러한 교훈은 단순 병합이 아니라 심볼적 해석(symbolic interpretation)과 분산표현 기반 추론(distributed reasoning)을 구조적으로 통합하는 새로운 아키텍처가 필요함을 분명히 보여준다. 이는 다양한 추론 경로를 명시적으로 해석하고, 그 과정의 정당성과 적절성을 평가하면서도 LLM의 표현력(expressivity)과 확장성(scalability)을 유지할 수 있어야 한다. 이러한 문제의식이 본 연구에서 제안하는 **SIREN(Symbol Interpretation and Reasoning Explanation Network)**의 출발점이다.


## 연구 내용 

1. 표현 공간 설계
  - 다중값 기반 심볼 
  - 공격, 지지기반 심볼 관계망 
  - 심볼 최종 평가  

2. 확장 가능성을 고려한 프레임워크 설계 
  - Interpretation I (심볼 해석)
  - Interpretation II (표현 해석)

3. 유틸리티적 모듈 
   - 기여도 측정 
   - 컨텍스트 적용 모듈 

## 

---


